{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41efb2fb",
   "metadata": {},
   "source": [
    "##### BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc5e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do Cuda: 2.9.0+cu130\n",
      "Disponibilidade da GPU: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import zipfile\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "import librosa\n",
    "import parselmouth\n",
    "\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f'Versão do Cuda: {torch.__version__}')\n",
    "print(f'Disponibilidade da GPU: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59655bad",
   "metadata": {},
   "source": [
    "##### EXTRAÇÃO DAS FEATURES\n",
    "\n",
    "- Fo(Hz): A frequência fundamental, que representa a altura média da voz.\n",
    "- Fhi(Hz): A frequência fundamental máxima, que indica a altura mais alta do sinal de voz.\n",
    "- Flo(Hz): A frequência fundamental mínima, que representa a altura mais baixa do sinal de voz.\n",
    "\n",
    "- Jitter:\n",
    "    - Jitter(%): Representa a porcentagem de variação de frequência (jitter) na voz, indicando irregularidades na altura.\n",
    "    - Jitter(Abs): Jitter absoluto, que mede a quantidade bruta de perturbação de frequência.\n",
    "    - RAP, PPQ, DDP: Métricas de jitter específicas adicionais que ajudam a quantificar as variações de frequência ao longo do tempo, oferecendo diferentes maneiras de calcular irregularidades na altura.\n",
    "\n",
    "- Shimmer: Mede a variação de amplitude, indicando a flutuação na intensidade do sinal de voz.\n",
    "- Shimmer(dB): Uma versão do shimmer baseada em decibéis que quantifica as perturbações de amplitude em unidades logarítmicas.\n",
    "- Shimmer:APQ3, Shimmer:APQ5, MDVP:APQ, Shimmer:DDA: Várias métricas de shimmer que avaliam diferentes aspectos da instabilidade de amplitude, incluindo variações de curto e longo prazo.\n",
    "\n",
    "- NHR: Quantifica a quantidade de ruído em relação aos componentes harmônicos da voz, fornecendo informações sobre a qualidade vocal. Um NHR mais alto sugere um sinal de voz mais ruidoso.\n",
    "- HNR: Mede a proporção entre harmônicos (sinal de voz nítido) e ruído. Um valor mais alto indica melhor clareza do sinal de voz e menos ruído.\n",
    "\n",
    "- RPDE: Entropia da densidade do período de recorrência, uma medida da complexidade e periodicidade do sinal de voz.\n",
    "- DFA: Análise de flutuação detendenciada, um método usado para analisar a autossimilaridade do sinal de voz, revelando dependências de longo prazo e comportamento fractal.\n",
    "- spread1, spread2: Medidas de variações na dispersão do sinal, que ajudam a entender como o sinal flutua ao longo do tempo.\n",
    "- D2: Dimensão de correlação, uma métrica para medir a complexidade e o número de dimensões no sinal. Ela ajuda a quantificar a complexidade dinâmica do sinal de voz.\n",
    "- PPE: A entropia do período de altura quantifica a irregularidade ou desordem nos períodos de altura, indicando o nível de imprevisibilidade no sinal de voz.\n",
    "\n",
    "Acho que a melhor forma de fazer isso é dividir em blocos:\n",
    "- Extração de F0 e estatísticas básicas (Fo, Fhi, Flo)\n",
    "- Extração de perturbações de frequência e amplitude (Jitter e Shimmer, com todas as variações)\n",
    "- Extração de medidas não lineares (RPDE, DFA, D2, spread1, spread2, PPE)\n",
    "\n",
    "A função que usa Praat para as medidas clássicas e librosa + métodos numéricos para as medidas não lineares (RPDE, DFA etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b88321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    snd = parselmouth.Sound(audio_path)\n",
    "\n",
    "    try:\n",
    "        pitch = snd.to_pitch(pitch_floor=75.0, pitch_ceiling=600.0)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular Pitch (to_pitch): {e}\", file=sys.stderr)\n",
    "        return np.full(8, np.nan, dtype=np.float64)\n",
    "\n",
    "    f0_values = np.array(pitch.selected_array['frequency'], dtype=np.float64)\n",
    "    f0_values = f0_values[f0_values > 0]\n",
    "    f0_values_filtered = f0_values[(f0_values > 50) & (f0_values < 500)]\n",
    "    \n",
    "    if len(f0_values_filtered) == 0:\n",
    "        f0_mean = f0_max = f0_min = f0_std = np.nan\n",
    "    else:\n",
    "        f0_mean = np.mean(f0_values_filtered)\n",
    "        f0_max  = np.max(f0_values_filtered)\n",
    "        f0_min  = np.min(f0_values_filtered)\n",
    "        f0_std  = np.std(f0_values_filtered)\n",
    "\n",
    "    try:\n",
    "        pointProcess = parselmouth.praat.call(snd, \"To PointProcess (periodic, cc)\", 75.0, 600.0)\n",
    "        jitter_local = parselmouth.praat.call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "        shimmer_local_percent = parselmouth.praat.call([snd, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "        hnr = parselmouth.praat.call(snd, \"To Harmonicity (cc)\", 0.01, 75.0, 0.1, 1.0)\n",
    "        hnr_value = parselmouth.praat.call(hnr, \"Get mean\", 0, 0)\n",
    "        \n",
    "        nhr = 10 ** (-hnr_value / 10) if hnr_value > 0 else np.nan\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na extração Praat (Jitter/Shimmer/HNR): {e}\", file=sys.stderr)\n",
    "        jitter_local = shimmer_local_percent = hnr_value = nhr = np.nan\n",
    "        \n",
    "    features = [\n",
    "        f0_mean,\n",
    "        f0_max,\n",
    "        f0_min,\n",
    "        f0_std,\n",
    "        jitter_local,\n",
    "        shimmer_local_percent,\n",
    "        hnr_value,\n",
    "        nhr\n",
    "    ]\n",
    "    return np.array(features, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178b43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    snd = parselmouth.Sound(audio_path)\n",
    "\n",
    "    # =========================\n",
    "    # 1. Pitch (Fo, Fhi, Flo)\n",
    "    # =========================\n",
    "    try:\n",
    "        pitch = snd.to_pitch(pitch_floor=75.0, pitch_ceiling=600.0)\n",
    "        f0_values = np.array(pitch.selected_array['frequency'], dtype=np.float64)\n",
    "        f0_values = f0_values[f0_values > 0]\n",
    "\n",
    "        if len(f0_values) == 0:\n",
    "            Fo = Fhi = Flo = np.nan\n",
    "        else:\n",
    "            Fo = np.mean(f0_values)\n",
    "            Fhi = np.max(f0_values)\n",
    "            Flo = np.min(f0_values)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular Pitch: {e}\", file=sys.stderr)\n",
    "        Fo = Fhi = Flo = np.nan\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. Jitter, Shimmer, NHR, HNR (via Praat)\n",
    "    # ==========================================\n",
    "    try:\n",
    "        pointProcess = parselmouth.praat.call(snd, \"To PointProcess (periodic, cc)\", 75.0, 600.0)\n",
    "\n",
    "        # --- Jitter ---\n",
    "        jitter_percent = parselmouth.praat.call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3) * 100\n",
    "        jitter_abs = parselmouth.praat.call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "        rap = parselmouth.praat.call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "        ppq = parselmouth.praat.call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "        ddp = parselmouth.praat.call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "        # --- Shimmer ---\n",
    "        shimmer_local = parselmouth.praat.call([snd, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        shimmer_db = parselmouth.praat.call([snd, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        apq3 = parselmouth.praat.call([snd, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        apq5 = parselmouth.praat.call([snd, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        apq11 = parselmouth.praat.call([snd, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        dda = parselmouth.praat.call([snd, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "\n",
    "        # --- Harmonicity / Noise ---\n",
    "        harmonicity = parselmouth.praat.call(snd, \"To Harmonicity (cc)\", 0.01, 75.0, 0.1, 1.0)\n",
    "        HNR = parselmouth.praat.call(harmonicity, \"Get mean\", 0, 0)\n",
    "        NHR = 10 ** (-HNR / 10) if HNR > 0 else np.nan\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular Jitter/Shimmer/HNR: {e}\", file=sys.stderr)\n",
    "        jitter_percent = jitter_abs = rap = ppq = ddp = np.nan\n",
    "        shimmer_local = shimmer_db = apq3 = apq5 = apq11 = dda = np.nan\n",
    "        HNR = NHR = np.nan\n",
    "\n",
    "    # =======================================\n",
    "    # 3. Nonlinear features (RPDE, DFA, D2)\n",
    "    # =======================================\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        # RPDE (Recurrence Period Density Entropy)\n",
    "        rpde = np.std(np.diff(y)) / np.mean(np.abs(y)) if np.mean(np.abs(y)) != 0 else np.nan\n",
    "\n",
    "        # DFA (Detrended Fluctuation Analysis)\n",
    "        def compute_dfa(signal):\n",
    "            n = len(signal)\n",
    "            signal = np.cumsum(signal - np.mean(signal))\n",
    "            scales = np.floor(np.logspace(np.log10(4), np.log10(n / 4), num=20)).astype(int)\n",
    "            fluct = []\n",
    "            for s in scales:\n",
    "                shape = (n // s, s)\n",
    "                rms = []\n",
    "                for segment in np.array_split(signal[:shape[0]*shape[1]], shape[0]):\n",
    "                    coeffs = np.polyfit(range(s), segment, 1)\n",
    "                    trend = np.polyval(coeffs, range(s))\n",
    "                    rms.append(np.sqrt(np.mean((segment - trend) ** 2)))\n",
    "                fluct.append(np.sqrt(np.mean(np.array(rms) ** 2)))\n",
    "            coeffs = np.polyfit(np.log(scales), np.log(fluct), 1)\n",
    "            return coeffs[0]\n",
    "\n",
    "        dfa = compute_dfa(y)\n",
    "\n",
    "        # Spread1 e Spread2 (estatísticas do espectro)\n",
    "        S, phase = librosa.magphase(librosa.stft(y))\n",
    "        centroid = librosa.feature.spectral_centroid(S=S)\n",
    "        bandwidth = librosa.feature.spectral_bandwidth(S=S)\n",
    "        spread1 = np.mean(centroid)\n",
    "        spread2 = np.mean(bandwidth)\n",
    "\n",
    "        # D2 (Dimensão de correlação simples)\n",
    "        d2 = np.log(np.var(y)) if np.var(y) > 0 else np.nan\n",
    "\n",
    "        # PPE (Pitch Period Entropy)\n",
    "        pitch_values = f0_values[f0_values > 0]\n",
    "        if len(pitch_values) > 0:\n",
    "            prob, _ = np.histogram(pitch_values, bins=20, density=True)\n",
    "            prob = prob[prob > 0]\n",
    "            ppe = -np.sum(prob * np.log2(prob))\n",
    "        else:\n",
    "            ppe = np.nan\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular medidas não lineares: {e}\", file=sys.stderr)\n",
    "        rpde = dfa = spread1 = spread2 = d2 = ppe = np.nan\n",
    "\n",
    "    # =======================\n",
    "    # 4. Vetor final de saída\n",
    "    # =======================\n",
    "    features = [\n",
    "        Fo, Fhi, Flo,\n",
    "        jitter_percent, jitter_abs, rap, ppq, ddp,\n",
    "        shimmer_local, shimmer_db, apq3, apq5, apq11, dda,\n",
    "        NHR, HNR,\n",
    "        rpde, dfa, spread1, spread2, d2, ppe\n",
    "    ]\n",
    "\n",
    "    return np.array(features, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda48bb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "12 columns passed, passed data had 26 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m939\u001b[39m     columns = \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[39m, in \u001b[36m_validate_or_indexify_columns\u001b[39m\u001b[34m(content, columns)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) != \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    987\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns passed, passed data had \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    988\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    989\u001b[39m     )\n\u001b[32m    990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[32m    991\u001b[39m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: 12 columns passed, passed data had 26 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     49\u001b[39m                 \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mErro no arquivo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, file=sys.stderr)\n\u001b[32m     52\u001b[39m columns = [\u001b[33m'\u001b[39m\u001b[33mID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAge\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSex\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m] + features_names\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m output_csv = \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mjoaov_zm1q2wh\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\\\u001b[39m\u001b[33micassp_challenge\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mjoao\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mfeatures.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     55\u001b[39m df.to_csv(output_csv, index=\u001b[38;5;28;01mFalse\u001b[39;00m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8-sig\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:855\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    853\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    854\u001b[39m         columns = ensure_index(columns)\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m     arrays, columns, index = \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[32m    858\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    863\u001b[39m     mgr = arrays_to_mgr(\n\u001b[32m    864\u001b[39m         arrays,\n\u001b[32m    865\u001b[39m         columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    868\u001b[39m         typ=manager,\n\u001b[32m    869\u001b[39m     )\n\u001b[32m    870\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[39m, in \u001b[36mnested_data_to_arrays\u001b[39m\u001b[34m(data, columns, index, dtype)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[32m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    518\u001b[39m     columns = ensure_index(data[\u001b[32m0\u001b[39m]._fields)\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m arrays, columns = \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m columns = ensure_index(columns)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[39m, in \u001b[36mto_arrays\u001b[39m\u001b[34m(data, columns, dtype)\u001b[39m\n\u001b[32m    842\u001b[39m     data = [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m    843\u001b[39m     arr = _list_to_arrays(data)\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m content, columns = \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    939\u001b[39m     columns = _validate_or_indexify_columns(contents, columns)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[32m0\u001b[39m].dtype == np.object_:\n\u001b[32m    945\u001b[39m     contents = convert_object_array(contents, dtype=dtype)\n",
      "\u001b[31mValueError\u001b[39m: 12 columns passed, passed data had 26 columns"
     ]
    }
   ],
   "source": [
    "zip_path = r'C:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\joao\\data\\SAND_Challenge_task1_dataset.zip'\n",
    "target_folder = 'task1/training/rhythmTA'\n",
    "metadata_path = 'task1/sand_task_1.xlsx'\n",
    "\n",
    "features_names = [\n",
    "    \"F0_mean_Hz\", \n",
    "    \"F0_max_Hz\", \n",
    "    \"F0_min_Hz\", \n",
    "    \"F0_std_Hz\",\n",
    "    \"Jitter_percent\", \n",
    "    \"Shimmer_percent\", \n",
    "    \"HNR_dB\", \n",
    "    \"NHR\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "    with zipf.open(metadata_path) as meta_file:\n",
    "        metadata_df = pd.read_excel(meta_file)\n",
    "    \n",
    "    for file in zipf.namelist():\n",
    "        if file.startswith(target_folder) and file.endswith('.wav'):\n",
    "            try:\n",
    "                with zipf.open(file) as audio_file:\n",
    "                    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp:\n",
    "                        tmp.write(audio_file.read())\n",
    "                        tmp_path = tmp.name\n",
    "\n",
    "                features = extract_features(tmp_path)\n",
    "\n",
    "                os.remove(tmp_path)\n",
    "\n",
    "                filename = os.path.basename(file)\n",
    "                sample_id = filename.split(\"_\")[0]\n",
    "\n",
    "                meta_row = metadata_df.loc[metadata_df[\"ID\"] == sample_id]\n",
    "                if not meta_row.empty:\n",
    "                    age  = int(meta_row[\"Age\"].values[0])\n",
    "                    sex  = meta_row[\"Sex\"].values[0]\n",
    "                    clas = int(meta_row[\"Class\"].values[0])\n",
    "                else:\n",
    "                    age = sex = clas = np.nan\n",
    "\n",
    "                row = [sample_id, age, sex, clas] + list(features)\n",
    "                data.append(row)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Erro no arquivo {file}: {e}', file=sys.stderr)\n",
    "\n",
    "\n",
    "columns = ['ID', 'Age', 'Sex', 'Class'] + features_names\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "output_csv = r'C:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\joao\\data\\features.csv'\n",
    "df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print('Extração concluída!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577564c5",
   "metadata": {},
   "source": [
    "##### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\joao\\data\\features_all.csv')\n",
    "\n",
    "# X = df.drop(columns=[\"ID\", \"Class\"])\n",
    "# y = df[\"Class\"]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "# X_scaled_df.to_csv(r'C:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\joao\\data\\features_normalized_column.csv', index=False)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=200,\n",
    "#     max_depth=15,\n",
    "#     min_samples_leaf=5,\n",
    "#     max_features='sqrt',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# y_train_pred = rf.predict(X_train)\n",
    "# y_test_pred = rf.predict(X_test)\n",
    "\n",
    "# print(\"Acurácia treino:\", accuracy_score(y_train, y_train_pred))\n",
    "# print(\"Acurácia teste:\", accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# print(\"\\nRelatório de classificação (teste):\")\n",
    "# print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# print(\"\\nMatriz de confusão (teste):\")\n",
    "# print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "# importances.nlargest(20).sort_values().plot(kind=\"barh\", figsize=(8, 6), title=\"Top 20 Features Importantes\")\n",
    "# plt.show()\n",
    "\n",
    "# cm = confusion_matrix(y_test, y_test_pred)\n",
    "# labels = sorted(y_test.unique())\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "# plt.xlabel(\"Predito\")\n",
    "# plt.ylabel(\"Real\")\n",
    "# plt.title(\"Matriz de Confusão\")\n",
    "# plt.show()\n",
    "\n",
    "# df = pd.read_csv(r'C:\\Users\\joaov_zm1q2wh\\python\\icassp_challenge\\joao\\data\\features_all.csv')\n",
    "\n",
    "# cols_to_drop = [col for col in df.columns if col.startswith(\"NHR\")]\n",
    "# cols_to_drop = [col for col in df.columns if col.startswith(\"F0_max\")]\n",
    "# cols_to_drop = [col for col in df.columns if col.startswith(\"F0_min\")]\n",
    "# # cols_to_drop = [col for col in df.columns if col.startswith(\"Age\")]\n",
    "# # cols_to_drop = [col for col in df.columns if col.startswith(\"Sex\")]\n",
    "\n",
    "# df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# test_ids = [\n",
    "#     \"ID007\",\"ID012\",\"ID021\",\"ID029\",\"ID037\",\"ID046\",\"ID051\",\"ID053\",\"ID054\",\"ID056\",\n",
    "#     \"ID063\",\"ID075\",\"ID083\",\"ID090\",\"ID099\",\"ID101\",\"ID105\",\"ID110\",\"ID116\",\"ID122\",\n",
    "#     \"ID129\",\"ID136\",\"ID138\",\"ID140\",\"ID158\",\"ID160\",\"ID164\",\"ID171\",\"ID176\",\"ID179\",\n",
    "#     \"ID202\",\"ID209\",\"ID227\",\"ID229\",\"ID233\",\"ID245\",\"ID252\",\"ID253\",\"ID260\",\"ID261\",\n",
    "#     \"ID263\",\"ID264\",\"ID269\",\"ID270\",\"ID274\",\"ID278\",\"ID284\",\"ID286\",\"ID290\",\"ID302\",\n",
    "#     \"ID306\",\"ID323\",\"ID329\"\n",
    "# ]\n",
    "\n",
    "# train_df = df[~df[\"ID\"].isin(test_ids)].reset_index(drop=True)\n",
    "# test_df  = df[df[\"ID\"].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "# X_train = train_df.drop(columns=[\"ID\", \"Class\"])\n",
    "# y_train = train_df[\"Class\"]\n",
    "\n",
    "# X_test = test_df.drop(columns=[\"ID\", \"Class\"])\n",
    "# y_test = test_df[\"Class\"]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=200,\n",
    "#     max_depth=15,\n",
    "#     min_samples_leaf=5,\n",
    "#     max_features='sqrt',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# y_train_pred = rf.predict(X_train_scaled)\n",
    "# y_test_pred  = rf.predict(X_test_scaled)\n",
    "\n",
    "# print(\"Acurácia treino:\", accuracy_score(y_train, y_train_pred))\n",
    "# print(\"Acurácia teste:\", accuracy_score(y_test, y_test_pred))\n",
    "# print(\"\\nRelatório de classificação (teste):\")\n",
    "# print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# cm = confusion_matrix(y_test, y_test_pred)\n",
    "# labels = sorted(y_test.unique())\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "# plt.xlabel(\"Predito\")\n",
    "# plt.ylabel(\"Real\")\n",
    "# plt.title(\"Matriz de Confusão\")\n",
    "# plt.show()\n",
    "\n",
    "# avg_f1_score = f1_score(y_test, y_test_pred, average='macro')\n",
    "# print(\"Average F1-score (teste):\", avg_f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
